# SALES PREDICTION TEST - GABRIEL SOUZA

#Importing usefull libraries
import tensorflow as tf
from tensorflow import keras
import pandas as pd
import datetime
from datetime import date
from datetime import timedelta 
from datetime import datetime
import plotly.graph_objects as go
import bt
import matplotlib as mtb
from matplotlib import pyplot as plt
%matplotlib inline
import seaborn as sns
import numpy as np
import plotly.express as px
import sklearn
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from xgboost import XGBRegressor
import pickle

#This notebook is left basically as an calc memory. Just so you can see the way through the thinking and not only the result of it

#Just taking a look at the data
df_raw_train=pd.read_csv('train.csv') 
df_raw_train.head()

df_raw_sub=pd.read_csv('test.csv') 
df_raw_sub.head()

df_raw_train.shape

df_raw_train.info()

df_raw_train_stats = df_raw_train.describe(include='all')
df_raw_train_stats = df_raw_train_stats.transpose()
df_raw_train_stats

list_user_id=list (df_raw_train['User_ID'].drop_duplicates())
len (list_user_id)

list_product_id=list (df_raw_train['Product_ID'].drop_duplicates())
len (list_product_id)

list_occupation=list (df_raw_train['Occupation'].drop_duplicates())
len (list_occupation)

list_pc1=list (df_raw_train['Product_Category_1'].drop_duplicates())
len (list_pc1)

list_pc2=list (df_raw_train['Product_Category_2'].drop_duplicates())
len (list_pc2)

list_pc3=list (df_raw_train['Product_Category_3'].drop_duplicates())
len (list_pc3)

df_eda=df_raw_train.copy()

#First takeaways are: lots of NA for product category #2 and #3. Must explore it and see if there's a pattern

#lowering the headers so we don't get crazy
lower_columns=df_eda.columns.to_list()
lower_columns= [column.lower() for column in lower_columns]
df_eda.columns = lower_columns

#First approach for the categorical features. For printing reasons I've left it with the label encoder and not the one hot encoding, since user_id and product_id amont of unic values would generate a huge dataframe making a difficult visual.
label_encoder = LabelEncoder()
to_be_coded_columns = ['user_id', 'product_id', 'gender', 'age', 'city_category', 'stay_in_current_city_years']
for column in to_be_coded_columns:
    df_eda[column+'_coded']=label_encoder.fit_transform(df_eda[column])

df_eda=df_eda.drop(to_be_coded_columns, axis=1)

#Let's see what we have for that product_id NAs.

z = df_eda['product_id_coded'].value_counts()

z

df_mask=df_eda['product_id_coded']==249
df_man = df_eda[df_mask]
df_man.shape

df_man.head()

#Taking a closer look at the user ID you can see that we're dealing with sub-categories, since for each product_id you got always the same values for product_categories one to tree.

df_eda.fillna(0, inplace=True)

df_eda['product_mean'] = df_eda['product_id_coded'].map(df_eda['purchase'].groupby(df_eda['product_id_coded']).mean())
df_eda['product_mean'] = df_eda['product_mean'].replace(np.nan, 0)

df_eda.info()

#MUCH BETTER NOW WITH NO NAs

##It takes a while but this is one good way to take a look at the whole data
#sns.pairplot(df_eda, diag_kind='kde')

#hmmmm product_category_1 has a very binned relation with the purchase. Interesting. 
#Also you can see the concentration on gender and age.
#Worth noticing that the purchase seems "spiky". That seems to bins in prices (confirmed by the following plot)
#Not really any outliers

correlation=df_eda
corr = correlation.corr()
fig = px.imshow(corr, range_color=[-1,1])
fig.show()

#From the correlation plots you have very few stuff over 0,3. bad news.

#Closer look at the product_category_1 bins we talked previously
fig=px.scatter(df_eda, x='purchase', y='product_category_1', hover_data=['product_category_2', 'product_category_3', 'product_id_coded'])
fig.show()

df_eda2=df_eda[['product_category_1','purchase']]

sns.pairplot(df_eda2, diag_kind="kde")

#Product_category_1 bins number 1, 5 and 8 are responsible for much of the income.
fig = px.histogram(df_eda, x="product_category_1", y='purchase', histnorm='probability density')
fig.show()

fig = px.histogram(df_eda, x="product_category_1", y='purchase', histfunc='avg')
fig.show()

med_list = []
for cat in list (range (1,21)):
    df_mask=df_eda['product_category_1']==cat
    df_temp = df_eda[df_mask]
    med_cat = df_temp['purchase'].median()
    med_list.append(med_cat)
med_list

mean_list = []
for cat in list (range (1,21)):
    df_mask=df_eda['product_category_1']==cat
    df_temp = df_eda[df_mask]
    mean_cat = df_temp['purchase'].mean()
    mean_list.append(mean_cat)
mean_list





df_raw_train.columns

df_clean_train = df_raw_train.copy()

from scipy import stats

df_clean_train = df_clean_train[(np.abs(stats.zscore(df_clean_train['Purchase']))<3)]

df_clean_train.shape

df_work = pd.concat([df_clean_train, df_raw_sub], ignore_index=True, sort=False)
df_clean_train.shape, df_raw_sub.shape, df_work.shape

df_work.tail()

#lowering the headers so we don't get crazy
lower_columns=df_work.columns.to_list()
lower_columns= [column.lower() for column in lower_columns]
df_work.columns = lower_columns

#First approach for the categorical features. For printing reasons I've left it with the label encoder and not the one hot encoding, since user_id and product_id amont of unic values would generate a huge dataframe making a difficult visual.
label_encoder = LabelEncoder()
to_be_coded_columns = ['user_id', 'product_id', 'gender', 'age', 'city_category', 'stay_in_current_city_years']
for column in to_be_coded_columns:
    df_work[column+'_coded']=label_encoder.fit_transform(df_work[column])

df_work=df_work.drop(to_be_coded_columns, axis=1)

df_work['product_mean'] = df_work['product_id_coded'].map(df_work['purchase'].groupby(df_work['product_id_coded']).mean())
df_work['product_mean'] = df_work['product_mean'].replace(np.nan, 0)



#Enough talking. Let's see what the ML libraries bring to us. That product_category_1 looks important

#let's make the initial features selection and firsts predictions

df_dum = df_work.copy()

df_dum.shape

a=df_dum.pop('purchase')
b=df_dum


columns = b.columns

b.fillna(0, inplace=True)

b = StandardScaler().fit_transform(b)

b= pd.DataFrame(b)

b.columns=columns

a=a.dropna()

b.head()

b.tail()

c=b.drop(b.tail(df_raw_sub.shape[0]).index)

c.shape

d=b.drop(b.head(df_clean_train.shape[0]).index)

d.shape

X_train, X_test, y_train, y_test = train_test_split(c, a, test_size=0.3)

d.pop('user_id_coded') 
d.pop('product_id_coded') 
X_train.pop('user_id_coded') 
X_train.pop('product_id_coded') 
X_test.pop('user_id_coded')  
X_test.pop('product_id_coded')  

x_naive_test = X_test.copy()

x_naive_test.columns

scaled_pc1_list = list (x_naive_test['product_category_1'].drop_duplicates())

scaled_pc1_list

naive_scaled_dict={}
naive_scaled_dict = dict(zip(scaled_pc1_list, mean_list))

naive_scaled_dict

type (naive_scaled_dict)

x_naive_test['prediction'] = x_naive_test['product_category_1'].apply(lambda x: naive_scaled_dict[x])

naive_prediction = x_naive_test['prediction']

mae = round (mean_absolute_error(y_test, naive_prediction), 2)
mse = round (mean_squared_error(y_test, naive_prediction), 2)
r2 = round (r2_score(y_test, naive_prediction), 2)
rmse = round (np.sqrt(mse), 2)
print (mae, mse, rmse, r2)



rfr=RandomForestRegressor(n_estimators = 120, max_depth=10)

rfr.fit(X_train, y_train)

importances = rfr.feature_importances_

plt.bar(height=importances, x=X_train.columns)
plt.xticks(rotation='vertical')
plt.show()

prediction = rfr.predict(X_test)

mae = round (mean_absolute_error(y_test, prediction), 2)
mse = round (mean_squared_error(y_test, prediction), 2)
r2 = round (r2_score(y_test, prediction), 2)
rmse = round (np.sqrt(mse), 2)
print (mae, mse, rmse, r2)

#Pkl_Filename = "sales_prediction_rfr.pkl"  

#with open(Pkl_Filename, 'wb') as file:  
#    pickle.dump(rfr, file)

modelo_xbg =  XGBRegressor(objective ='reg:squarederror', 
                           n_estimators = 400, min_child_weight=5, max_depth=9, gamma=0.1, random_state=7, n_jobs=4)
                                                          
modelo_xbg.fit(X_train, y_train)

xgb_test_prediction = modelo_xbg.predict(X_test)

mae = round (mean_absolute_error(y_test, xgb_test_prediction), 2)
mse = round (mean_squared_error(y_test, xgb_test_prediction), 2)
r2 = round (r2_score(y_test, xgb_test_prediction), 2)
rmse = round (np.sqrt(mse), 2)
print (mae, mse, rmse, r2)

#Pkl_Filename = "sales_prediction_xbg.pkl"  

#with open(Pkl_Filename, 'wb') as file:  
#    pickle.dump(modelo_xbg, file)

TT

rfr_prediction = rfr.predict(d)

submission_df=df_raw_sub[['User_ID', 'Product_ID']]

submission_df['Purchase']=rfr_prediction

submission_df.describe(include='all')

submission_df.to_csv('submission_80.csv',index=False)



xgb_prediction = modelo_xbg.predict(d)

submission_df=df_raw_sub[['User_ID', 'Product_ID']]

submission_df['Purchase']=xgb_prediction

submission_df.describe(include='all')

submission_df.head()

#Checking if prediction distribution looks like train data distribution

fig = px.histogram(submission_df, x='Purchase', histnorm='probability density')
fig.show()

fig = px.histogram(df_eda, x='purchase', histnorm='probability density')
fig.show()

#Yep. Prediction distribution looks like train data.

#Visual aid of what we noted before: right trend, but wide errors
fig=px.scatter(x=y_test, y=xgb_test_prediction, trendline='ols')
fig.show()

evaluation = pd.DataFrame()
evaluation['labels'] = y_test
evaluation['prediction'] = xgb_test_prediction
evaluation['error'] = evaluation['prediction'] - evaluation['labels']

fig = px.scatter(evaluation, x="prediction", y='error', trendline='ols')
fig.show()

fig = px.histogram(evaluation, x='error')
fig.show()

#error looks kind of "normal", which is good but has a way to big kurtosis.

fig = px.histogram(evaluation, x="prediction", y='error', nbins=10, histfunc='avg')
fig.show()

#We're doing better at low purchase values
#Due to the nature of the test data (randomly selected), one alternative would be to correct models forcast by the average error of each bin above and check at traindata if it would e much of an overfitting. 
#But for the robustness to a general case where not necessarily data would be randomly selected and we have more data to understand if there's a trend in time, for example, I'll let the example as it is.

submission_df['Purchase_rect'] = submission_df['Purchase'].apply(lambda x: 0.00 if x <=0 else x)

submission_df.describe()

submission_df.head()

submission_df = submission_df.drop(['Purchase'], axis=1)

submission_df.columns=(['User_ID', 'Product_ID', 'Purchase'])

submission_df.head()

submission_df.to_csv('submission_70.csv',index=False) #<-- this solution currently ranks at 545.

#Let's see if Keras regressor can help us

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

train_dataset = X_train.copy()
test_dataset = X_test.copy()
train_labels = y_train.copy()
test_labels = y_test.copy()

#This is a configuration I got from previous opportunities. Mixing ReLu and Swish activation help us to better reults, mainly due to beta parameter at Swish
def build_model():
  model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),
    layers.Dense(64, activation='relu'),
    layers.Dense(64, activation='swish'),
    layers.Dense(64, activation='relu'),
    layers.Dense(64, activation='swish'),
    layers.Dense(64, activation='relu'),
    layers.Dense(64, activation='swish'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.RMSprop(0.001)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

model = build_model()

# Mostra o progresso do treinamento imprimindo um único ponto para cada epoch completada
class PrintDot(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs):
    if epoch % 100 == 0: print('')
    print('.', end='')

EPOCHS = 100 #tried to 1000 as picture shown. But 200 is already to much

history = model.fit(
  train_dataset, train_labels,
  epochs=EPOCHS, validation_split = 0.2, verbose=0,
  callbacks=[PrintDot()])

hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

def plot_history(history):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Abs Error [purchase]')
  plt.plot(hist['epoch'], hist['mae'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mae'],
           label = 'Val Error')
  plt.ylim([2000,3000])
  plt.legend()

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error [$purchase^2$]')
  plt.plot(hist['epoch'], hist['mse'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
           label = 'Val Error')
  plt.ylim([800000,16000000])
  plt.legend()
  plt.show()


plot_history(history)

Yes I tried 1000 epochs... See that after a bit it becomes useless. Thank God for the earlystop callback
![image.png](attachment:image.png)

model2 = build_model()

# O parâmetro patience é o quantidade de epochs para checar as melhoras
early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

history2 = model2.fit(train_dataset, train_labels, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(history2)

loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)

print("Testing set Mean Abs Error: {:5.2f} purchase".format(mae))

loss, mae, mse = model2.evaluate(test_dataset, test_labels, verbose=2)

print("Testing set Mean Abs Error: {:5.2f} purchase".format(mae))

RMSE = round (np.sqrt(mse), 2)
RMSE

model2.save('keras_regressor_sales_prediction')

#mae: 2149.1245 - mse: 8623112.0000
#Well Keras didn't helped much at the forecasts errors

test_predictions = model.predict(test_dataset).flatten()

plt.scatter(test_labels, test_predictions)
plt.xlabel('True Values [purchase]')
plt.ylabel('Predictions [purchase]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])





#Let's see if we can change this to a classification issue trying to forecast the bins we saw. Let's try with the product_id_1
#Idea is: since Product_category_1 seems pretty binned, maybe with the other features we can classify purchase into one of eac Product_category_q bin.

fig=px.scatter(df_work2, x='purchase', y='product_category_1')
fig.show()

df_mask=df_work2['product_category_1']==1
df_man = df_work2[df_mask]

dtebins = [-1, 6000, 10000, 14000, 18000, 20000]
dtelabels = [1,2,3,4, 5]
#dtelabels = ['under_5','10_to_5','15_to_10','20_to_15', '25_to_20', '30_to_25', '30+']
df_man['binned'] = pd.cut(df_man['purchase'], bins=dtebins, labels=dtelabels)

correlation=df_man
corr = correlation.corr()
fig = px.imshow(corr, range_color=[-1,1])
fig.show()

sns.pairplot(df_man, diag_kind="kde")

df_mask=df_work2['product_category_1']==5
df_man = df_work2[df_mask]

dtebins = [-1,2500, 4000, 6000, 8000, 20000]
dtelabels = [1,2,3,4, 5]
#dtelabels = ['under_5','10_to_5','15_to_10','20_to_15', '25_to_20', '30_to_25', '30+']
df_man['binned'] = pd.cut(df_man['purchase'], bins=dtebins, labels=dtelabels)

correlation=df_man
corr = correlation.corr()
fig = px.imshow(corr, range_color=[-1,1])
fig.show()

sns.pairplot(df_man, diag_kind="kde")



fig = px.scatter(df_man, x='purchase', y='purchase')
fig.show()

X_test.shape

X_train.shape

from sklearn.ensemble import RandomForestClassifier

df_dum = df_man.copy()


df_dum.shape

a=df_dum.pop('binned')
b=df_dum
df_dum.pop('purchase')

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(b, a, test_size=0.3)

rfc=RandomForestClassifier(n_estimators = 100, max_depth=50)


sel = SelectFromModel(rfc)
sel.fit(X_train, y_train)

sel.get_support()

selected_feat= X_train.columns[(sel.get_support())]
print (selected_feat)

rfc.fit(X_train, y_train)

importances = rfc.feature_importances_

plt.bar(height=importances, x=X_train.columns)
plt.xticks(rotation='vertical')
plt.show()

prediction=rfc.predict(X_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test, prediction)

#0.37571828845514554 Accuracy. Not good at all

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, prediction)

#Confusion matrix shows that we could not find a pattern, through the less important features, to classify the purchases to a bin

TT

# WRAP UP

Not sistematically, but best performance was achieved with scaled traindata.
Sistematically best results were achieved with all columns, although the improvement was sometimes marginal.
Sistematically best performance was achieved with sklearn randomforest regressor.
For bigger datasets, would be important to drop the less important features to improve computational resources.
Average purchase value per product was an important feature
Definitelly it's a good idea, for this issue, to explore bins usage and classification in further explore
